"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ GPU —É—Å–∫–æ—Ä–µ–Ω–∏—è –∏ WebRTC —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ—Ö —É–ª—É—á—à–µ–Ω–∏–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
"""

import asyncio
import time
import requests
import numpy as np
import cv2
from typing import List, Dict
import json
import concurrent.futures
from pathlib import Path

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤
API_BASE_URL = "http://localhost:8000"
TEST_VIDEO_PATH = "test_video.mp4"
TEST_VIDEO_ID = "performance_test"

class PerformanceTester:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ GPU –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    
    def __init__(self, base_url: str = API_BASE_URL):
        self.base_url = base_url
        self.results = {}
    
    def create_test_video(self, duration: int = 10, fps: int = 30):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –≤–∏–¥–µ–æ"""
        print(f"üé¨ Creating test video: {duration}s @ {fps}fps")
        
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(TEST_VIDEO_PATH, fourcc, fps, (640, 480))
        
        total_frames = duration * fps
        for i in range(total_frames):
            # –°–æ–∑–¥–∞–µ–º –∫–∞–¥—Ä —Å –¥–≤–∏–∂—É—â–∏–º—Å—è –æ–±—ä–µ–∫—Ç–æ–º
            frame = np.zeros((480, 640, 3), dtype=np.uint8)
            
            # –§–æ–Ω
            frame[:] = (50, 50, 100)
            
            # –î–≤–∏–∂—É—â–∏–π—Å—è –∫—Ä—É–≥
            x = int(320 + 200 * np.sin(i * 0.1))
            y = int(240 + 100 * np.cos(i * 0.05))
            cv2.circle(frame, (x, y), 30, (0, 255, 0), -1)
            
            # –¢–µ–∫—Å—Ç —Å –Ω–æ–º–µ—Ä–æ–º –∫–∞–¥—Ä–∞
            cv2.putText(frame, f"Frame: {i}", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            
            out.write(frame)
        
        out.release()
        print(f"‚úÖ Test video created: {TEST_VIDEO_PATH}")
    
    def test_upload_performance(self):
        """–¢–µ—Å—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏ –∑–∞–≥—Ä—É–∑–∫–∏ —Å –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        print("\nüöÄ Testing GPU upload with indexing...")
        
        start_time = time.time()
        
        with open(TEST_VIDEO_PATH, 'rb') as f:
            files = {'file': f}
            data = {'id': TEST_VIDEO_ID}
            
            response = requests.post(
                f"{self.base_url}/api/gpu/video/upload",
                files=files,
                data=data
            )
        
        upload_time = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            self.results['upload'] = {
                'time': upload_time,
                'index_time': result.get('index_time', 'N/A'),
                'index_size': result.get('index_size', 'N/A'),
                'gpu_enabled': result.get('gpu_enabled', False),
                'device': result.get('device', 'N/A')
            }
            
            print(f"‚úÖ Upload completed in {upload_time:.2f}s")
            print(f"   üìä Index time: {result.get('index_time')}")
            print(f"   üìà Index size: {result.get('index_size')} entries")
            print(f"   üî• GPU enabled: {result.get('gpu_enabled')}")
            print(f"   üíª Device: {result.get('device')}")
        else:
            print(f"‚ùå Upload failed: {response.text}")
    
    def test_frame_access_speed(self, num_tests: int = 50):
        """–¢–µ—Å—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏ –¥–æ—Å—Ç—É–ø–∞ –∫ –∫–∞–¥—Ä–∞–º —á–µ—Ä–µ–∑ –∏–Ω–¥–µ–∫—Å"""
        print(f"\n‚ö° Testing frame access speed ({num_tests} requests)...")
        
        timestamps = np.linspace(0, 9, num_tests)  # 0-9 —Å–µ–∫—É–Ω–¥
        times = []
        
        for i, ts in enumerate(timestamps):
            start_time = time.time()
            
            response = requests.get(
                f"{self.base_url}/api/gpu/video/{TEST_VIDEO_ID}/frame",
                params={'t': ts, 'quality': 85}
            )
            
            request_time = time.time() - start_time
            times.append(request_time)
            
            if i % 10 == 0:
                print(f"   Frame {i+1}/{num_tests}: {request_time:.3f}s")
        
        avg_time = np.mean(times)
        min_time = np.min(times)
        max_time = np.max(times)
        
        self.results['frame_access'] = {
            'average_time': avg_time,
            'min_time': min_time,
            'max_time': max_time,
            'total_requests': num_tests
        }
        
        print(f"‚úÖ Average frame access: {avg_time:.3f}s")
        print(f"   üèÉ‚Äç‚ôÇÔ∏è Fastest: {min_time:.3f}s")
        print(f"   üêå Slowest: {max_time:.3f}s")
    
    def test_gpu_inference_performance(self, num_tests: int = 20):
        """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ GPU –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞"""
        print(f"\nüß† Testing GPU inference performance ({num_tests} requests)...")
        
        timestamps = np.linspace(0, 9, num_tests)
        times = []
        inference_times = []
        
        for i, ts in enumerate(timestamps):
            start_time = time.time()
            
            response = requests.get(
                f"{self.base_url}/api/gpu/video/{TEST_VIDEO_ID}/frame",
                params={'t': ts, 'inference': True, 'quality': 85}
            )
            
            total_time = time.time() - start_time
            times.append(total_time)
            
            if response.status_code == 200:
                inference_time = response.headers.get('X-Inference-Time', '0s')
                inference_times.append(float(inference_time.replace('s', '')))
                
                if i % 5 == 0:
                    print(f"   Inference {i+1}/{num_tests}: {total_time:.3f}s (GPU: {inference_time})")
        
        avg_total = np.mean(times)
        avg_inference = np.mean(inference_times) if inference_times else 0
        
        self.results['gpu_inference'] = {
            'average_total_time': avg_total,
            'average_inference_time': avg_inference,
            'total_requests': num_tests
        }
        
        print(f"‚úÖ Average total time: {avg_total:.3f}s")
        print(f"   üî• Average GPU inference: {avg_inference:.3f}s")
    
    def test_batch_inference(self, batch_sizes: List[int] = [1, 4, 8, 16]):
        """–¢–µ—Å—Ç batch –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ batch"""
        print(f"\nüì¶ Testing batch inference performance...")
        
        batch_results = {}
        
        for batch_size in batch_sizes:
            print(f"   Testing batch size: {batch_size}")
            
            timestamps = np.linspace(0, 9, batch_size).tolist()
            
            start_time = time.time()
            response = requests.post(
                f"{self.base_url}/api/gpu/video/{TEST_VIDEO_ID}/batch_inference",
                json=timestamps
            )
            processing_time = time.time() - start_time
            
            if response.status_code == 200:
                result = response.json()
                batch_results[batch_size] = {
                    'processing_time': processing_time,
                    'server_time': result.get('processing_time', 'N/A'),
                    'processed_frames': result.get('processed_frames', 0)
                }
                
                print(f"     ‚úÖ Batch {batch_size}: {processing_time:.3f}s total")
                print(f"        Server time: {result.get('processing_time')}")
            else:
                print(f"     ‚ùå Batch {batch_size} failed: {response.text}")
        
        self.results['batch_inference'] = batch_results
    
    def test_concurrent_access(self, num_concurrent: int = 10):
        """–¢–µ—Å—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∫ –∫–∞–¥—Ä–∞–º"""
        print(f"\nüîÄ Testing concurrent access ({num_concurrent} parallel requests)...")
        
        def get_random_frame():
            ts = np.random.uniform(0, 9)
            start_time = time.time()
            
            response = requests.get(
                f"{self.base_url}/api/gpu/video/{TEST_VIDEO_ID}/frame",
                params={'t': ts, 'quality': 85}
            )
            
            return time.time() - start_time, response.status_code == 200
        
        start_time = time.time()
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=num_concurrent) as executor:
            futures = [executor.submit(get_random_frame) for _ in range(num_concurrent)]
            results = [future.result() for future in concurrent.futures.as_completed(futures)]
        
        total_time = time.time() - start_time
        times = [r[0] for r in results]
        success_count = sum(r[1] for r in results)
        
        self.results['concurrent_access'] = {
            'total_time': total_time,
            'average_request_time': np.mean(times),
            'success_rate': success_count / num_concurrent,
            'concurrent_requests': num_concurrent
        }
        
        print(f"‚úÖ Concurrent test completed in {total_time:.2f}s")
        print(f"   üìä Average request time: {np.mean(times):.3f}s")
        print(f"   ‚úÖ Success rate: {success_count}/{num_concurrent}")
    
    def test_cache_performance(self):
        """–¢–µ—Å—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
        print(f"\nüíæ Testing cache performance...")
        
        # –ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å (cache miss)
        ts = 5.0
        start_time = time.time()
        response1 = requests.get(
            f"{self.base_url}/api/gpu/video/{TEST_VIDEO_ID}/frame",
            params={'t': ts, 'quality': 85}
        )
        miss_time = time.time() - start_time
        
        # –í—Ç–æ—Ä–æ–π –∑–∞–ø—Ä–æ—Å (cache hit)
        start_time = time.time()
        response2 = requests.get(
            f"{self.base_url}/api/gpu/video/{TEST_VIDEO_ID}/frame",
            params={'t': ts, 'quality': 85}
        )
        hit_time = time.time() - start_time
        
        cache_status1 = response1.headers.get('X-Cache-Status', 'UNKNOWN')
        cache_status2 = response2.headers.get('X-Cache-Status', 'UNKNOWN')
        
        self.results['cache_performance'] = {
            'miss_time': miss_time,
            'hit_time': hit_time,
            'speedup': miss_time / hit_time if hit_time > 0 else 0,
            'cache_status_1': cache_status1,
            'cache_status_2': cache_status2
        }
        
        print(f"‚úÖ Cache miss: {miss_time:.3f}s ({cache_status1})")
        print(f"‚úÖ Cache hit: {hit_time:.3f}s ({cache_status2})")
        print(f"üöÄ Cache speedup: {miss_time/hit_time:.1f}x" if hit_time > 0 else "N/A")
    
    def get_system_stats(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–∏—Å—Ç–µ–º—ã"""
        print(f"\nüìà Getting system statistics...")
        
        try:
            response = requests.get(f"{self.base_url}/api/gpu/stats")
            if response.status_code == 200:
                stats = response.json()
                self.results['system_stats'] = stats
                
                print("‚úÖ System Statistics:")
                gpu_info = stats.get('gpu_processor', {})
                print(f"   üî• Frames processed: {gpu_info.get('frames_processed', 'N/A')}")
                print(f"   üíæ Cache hit rate: {gpu_info.get('cache_hit_rate', 'N/A')}")
                print(f"   ‚ö° Avg inference time: {gpu_info.get('average_inference_time', 'N/A')}")
                print(f"   üì¶ Avg batch size: {gpu_info.get('average_batch_size', 'N/A')}")
                
                system_info = stats.get('system_info', {})
                print(f"   üéÆ GPU available: {system_info.get('gpu_available', False)}")
                print(f"   üíª GPU device: {system_info.get('gpu_device', 'N/A')}")
            else:
                print(f"‚ùå Failed to get stats: {response.text}")
        
        except Exception as e:
            print(f"‚ùå Error getting stats: {e}")
    
    def run_all_tests(self):
        """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        print("üß™ Starting comprehensive GPU performance tests...")
        print("=" * 60)
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤–æ–µ –≤–∏–¥–µ–æ
        self.create_test_video()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
        self.test_upload_performance()
        time.sleep(1)  # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É —Ç–µ—Å—Ç–∞–º–∏
        
        self.test_frame_access_speed()
        time.sleep(1)
        
        self.test_gpu_inference_performance()
        time.sleep(1)
        
        self.test_batch_inference()
        time.sleep(1)
        
        self.test_concurrent_access()
        time.sleep(1)
        
        self.test_cache_performance()
        time.sleep(1)
        
        self.get_system_stats()
        
        # –°–≤–æ–¥–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.print_summary()
    
    def print_summary(self):
        """–ü–µ—á–∞—Ç—å —Å–≤–æ–¥–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        print("\n" + "="*60)
        print("üìä PERFORMANCE TEST SUMMARY")
        print("="*60)
        
        if 'upload' in self.results:
            upload = self.results['upload']
            print(f"üì§ Upload Performance:")
            print(f"   Time: {upload['time']:.2f}s")
            print(f"   GPU: {upload['gpu_enabled']} ({upload['device']})")
            print(f"   Index: {upload['index_size']} entries in {upload['index_time']}")
        
        if 'frame_access' in self.results:
            frames = self.results['frame_access']
            print(f"\n‚ö° Frame Access:")
            print(f"   Average: {frames['average_time']:.3f}s")
            print(f"   Range: {frames['min_time']:.3f}s - {frames['max_time']:.3f}s")
        
        if 'gpu_inference' in self.results:
            gpu = self.results['gpu_inference']
            print(f"\nüß† GPU Inference:")
            print(f"   Total: {gpu['average_total_time']:.3f}s")
            print(f"   GPU only: {gpu['average_inference_time']:.3f}s")
        
        if 'cache_performance' in self.results:
            cache = self.results['cache_performance']
            print(f"\nüíæ Cache Performance:")
            print(f"   Speedup: {cache['speedup']:.1f}x")
            print(f"   Miss: {cache['miss_time']:.3f}s ‚Üí Hit: {cache['hit_time']:.3f}s")
        
        print(f"\nüéØ Recommendations:")
        
        if 'frame_access' in self.results:
            avg_time = self.results['frame_access']['average_time']
            if avg_time < 0.05:
                print(f"   ‚úÖ Excellent frame access speed ({avg_time:.3f}s)")
            elif avg_time < 0.1:
                print(f"   üëç Good frame access speed ({avg_time:.3f}s)")
            else:
                print(f"   ‚ö†Ô∏è  Frame access could be faster ({avg_time:.3f}s)")
        
        if 'cache_performance' in self.results:
            speedup = self.results['cache_performance']['speedup']
            if speedup > 5:
                print(f"   ‚úÖ Excellent cache performance ({speedup:.1f}x speedup)")
            elif speedup > 2:
                print(f"   üëç Good cache performance ({speedup:.1f}x speedup)")
            else:
                print(f"   ‚ö†Ô∏è  Cache could be more effective ({speedup:.1f}x speedup)")
        
        print("\nüèÅ Performance testing completed!")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        with open('performance_results.json', 'w') as f:
            json.dump(self.results, f, indent=2, default=str)
        print("üìÑ Results saved to: performance_results.json")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Ç–µ—Å—Ç–æ–≤"""
    print("üöÄ GPU Video Processing Performance Tester")
    print("üîß Make sure the GPU server is running on http://localhost:8000")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–µ—Ä–≤–µ—Ä–∞
    try:
        response = requests.get(f"{API_BASE_URL}/api/gpu/stats", timeout=5)
        if response.status_code == 200:
            print("‚úÖ Server is accessible")
        else:
            print("‚ö†Ô∏è  Server response not OK")
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Cannot connect to server: {e}")
        print("üí° Start the server with: python gpu_endpoints.py")
        return
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
    tester = PerformanceTester()
    tester.run_all_tests()

if __name__ == "__main__":
    main()
